{"version":3,"file":"index.js","sourceRoot":"","sources":["../../../../../../src/scraper/scrapeURL/engines/pdf/index.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,qCAA2D;AAG3D,+CAAiC;AACjC,2CAA8C;AAC9C,6BAAwB;AACxB,qDAAuC;AACvC,8DAAqC;AACrC,0DAAiC;AACjC,wDAAwE;AAIxE,KAAK,UAAU,uBAAuB,CAAC,IAAU,EAAE,YAAoB;IACnE,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,yCAAyC,EAAE,EAAE,YAAY,EAAE,CAAC,CAAC;IAE/E,MAAM,UAAU,GAAG,IAAI,QAAQ,EAAE,CAAC;IAElC,gDAAgD;IAChD,UAAU,CAAC,MAAM,CAAC,MAAM,EAAE;QACtB,CAAC,MAAM,CAAC,WAAW,CAAC,EAAE,MAAM;QAC5B,IAAI,EAAE,YAAY;QAClB,MAAM;YACF,OAAO,IAAA,0BAAgB,EAAC,YAAY,CAA0C,CAAA;QAClF,CAAC;QACD,WAAW;YACP,MAAM,KAAK,CAAC,yCAAyC,CAAC,CAAA;QAC1D,CAAC;QACD,IAAI,EAAE,CAAC,MAAM,kBAAE,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,IAAI;QACxC,IAAI;YACA,MAAM,KAAK,CAAC,kCAAkC,CAAC,CAAA;QACnD,CAAC;QACD,KAAK,CAAC,KAAK,EAAE,GAAG,EAAE,WAAW;YACzB,MAAM,KAAK,CAAC,mCAAmC,CAAC,CAAA;QACpD,CAAC;QACD,IAAI,EAAE,iBAAiB;KAClB,CAAC,CAAC;IAEX,MAAM,MAAM,GAAG,MAAM,IAAA,mBAAW,EAAC;QAC7B,GAAG,EAAE,oDAAoD;QACzD,MAAM,EAAE,MAAM;QACd,OAAO,EAAE;YACL,eAAe,EAAE,UAAU,OAAO,CAAC,GAAG,CAAC,kBAAkB,EAAE;SAC9D;QACD,IAAI,EAAE,UAAU;QAChB,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,MAAM,EAAE,4CAA4C,EAAE,CAAC;QACnF,MAAM,EAAE,OAAC,CAAC,MAAM,CAAC;YACb,EAAE,EAAE,OAAC,CAAC,MAAM,EAAE;SACjB,CAAC;KACL,CAAC,CAAC;IAEH,MAAM,KAAK,GAAG,MAAM,CAAC,EAAE,CAAC;IAExB,yBAAyB;IACzB,MAAM,MAAM,GAAG,MAAM,IAAA,mBAAW,EAAC;QAC7B,GAAG,EAAE,mDAAmD,KAAK,kBAAkB;QAC/E,MAAM,EAAE,KAAK;QACb,OAAO,EAAE;YACL,eAAe,EAAE,UAAU,OAAO,CAAC,GAAG,CAAC,kBAAkB,EAAE;SAC9D;QACD,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,MAAM,EAAE,4CAA4C,EAAE,CAAC;QACnF,MAAM,EAAE,OAAC,CAAC,MAAM,CAAC;YACb,QAAQ,EAAE,OAAC,CAAC,MAAM,EAAE;SACvB,CAAC;QACF,QAAQ,EAAE,EAAE;QACZ,WAAW,EAAE,GAAG;KACnB,CAAC,CAAC;IAEH,OAAO;QACH,QAAQ,EAAE,MAAM,CAAC,QAAQ;QACzB,IAAI,EAAE,MAAM,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,QAAQ,EAAE,EAAE,KAAK,EAAE,IAAI,EAAE,CAAC;KAC7D,CAAC;AACN,CAAC;AAED,KAAK,UAAU,qBAAqB,CAAC,IAAU,EAAE,YAAoB;IACjE,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,wCAAwC,EAAE,EAAE,YAAY,EAAE,CAAC,CAAC;IAE9E,MAAM,MAAM,GAAG,MAAM,IAAA,mBAAQ,EAAC,MAAM,kBAAE,CAAC,QAAQ,CAAC,YAAY,CAAC,CAAC,CAAC;IAC/D,MAAM,OAAO,GAAG,IAAA,qBAAU,EAAC,MAAM,CAAC,IAAI,CAAC,CAAC;IAExC,OAAO;QACH,QAAQ,EAAE,OAAO;QACjB,IAAI,EAAE,OAAO;KAChB,CAAC;AACN,CAAC;AAEM,KAAK,UAAU,SAAS,CAAC,IAAU;IACtC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE,CAAC;QACzB,MAAM,IAAI,GAAG,MAAM,IAAA,gCAAiB,EAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC/C,MAAM,OAAO,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC;QAC/C,OAAO;YACH,GAAG,EAAE,IAAI,CAAC,QAAQ,CAAC,GAAG;YACtB,UAAU,EAAE,IAAI,CAAC,QAAQ,CAAC,MAAM;YAEhC,IAAI,EAAE,OAAO;YACb,QAAQ,EAAE,OAAO;SACpB,CAAC;IACN,CAAC;IAED,MAAM,EAAE,QAAQ,EAAE,YAAY,EAAE,GAAG,MAAM,IAAA,2BAAY,EAAC,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,GAAG,CAAC,CAAC;IAEzE,IAAI,MAAM,GAA8B,IAAI,CAAC;IAC7C,IAAI,OAAO,CAAC,GAAG,CAAC,kBAAkB,EAAE,CAAC;QACjC,IAAI,CAAC;YACD,MAAM,GAAG,MAAM,uBAAuB,CAAC;gBACnC,GAAG,IAAI;gBACP,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,MAAM,EAAE,mCAAmC,EAAE,CAAC;aAC7E,EAAE,YAAY,CAAC,CAAC;QACrB,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACb,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,6DAA6D,EAAE,EAAE,KAAK,EAAE,CAAC,CAAC;YAC3F,MAAM,CAAC,gBAAgB,CAAC,KAAK,CAAC,CAAC;QACnC,CAAC;IACL,CAAC;IAED,IAAI,MAAM,KAAK,IAAI,EAAE,CAAC;QAClB,MAAM,GAAG,MAAM,qBAAqB,CAAC;YACjC,GAAG,IAAI;YACP,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,MAAM,EAAE,iCAAiC,EAAE,CAAC;SAC3E,EAAE,YAAY,CAAC,CAAC;IACrB,CAAC;IAED,MAAM,kBAAE,CAAC,MAAM,CAAC,YAAY,CAAC,CAAC;IAE9B,OAAO;QACH,GAAG,EAAE,QAAQ,CAAC,GAAG;QACjB,UAAU,EAAE,QAAQ,CAAC,MAAM;QAE3B,IAAI,EAAE,MAAM,CAAC,IAAI;QACjB,QAAQ,EAAE,MAAM,CAAC,QAAQ;KAC5B,CAAA;AACL,CAAC;AA5CD,8BA4CC","sourcesContent":["import { createReadStream, promises as fs } from \"node:fs\";\nimport { Meta } from \"../..\";\nimport { EngineScrapeResult } from \"..\";\nimport * as marked from \"marked\";\nimport { robustFetch } from \"../../lib/fetch\";\nimport { z } from \"zod\";\nimport * as Sentry from \"@sentry/node\";\nimport escapeHtml from \"escape-html\";\nimport PdfParse from \"pdf-parse\";\nimport { downloadFile, fetchFileToBuffer } from \"../utils/downloadFile\";\n\ntype PDFProcessorResult = {html: string, markdown?: string};\n\nasync function scrapePDFWithLlamaParse(meta: Meta, tempFilePath: string): Promise<PDFProcessorResult> {\n    meta.logger.debug(\"Processing PDF document with LlamaIndex\", { tempFilePath });\n\n    const uploadForm = new FormData();\n\n    // This is utterly stupid but it works! - mogery\n    uploadForm.append(\"file\", {\n        [Symbol.toStringTag]: \"Blob\",\n        name: tempFilePath,\n        stream() {\n            return createReadStream(tempFilePath) as unknown as ReadableStream<Uint8Array>\n        },\n        arrayBuffer() {\n            throw Error(\"Unimplemented in mock Blob: arrayBuffer\")\n        },\n        size: (await fs.stat(tempFilePath)).size,\n        text() {\n            throw Error(\"Unimplemented in mock Blob: text\")\n        },\n        slice(start, end, contentType) {\n            throw Error(\"Unimplemented in mock Blob: slice\")\n        },\n        type: \"application/pdf\",\n    } as Blob);\n\n    const upload = await robustFetch({\n        url: \"https://api.cloud.llamaindex.ai/api/parsing/upload\",\n        method: \"POST\",\n        headers: {\n            \"Authorization\": `Bearer ${process.env.LLAMAPARSE_API_KEY}`,\n        },\n        body: uploadForm,\n        logger: meta.logger.child({ method: \"scrapePDFWithLlamaParse/upload/robustFetch\" }),\n        schema: z.object({\n            id: z.string(),\n        }),\n    });\n\n    const jobId = upload.id;\n\n    // TODO: timeout, retries\n    const result = await robustFetch({\n        url: `https://api.cloud.llamaindex.ai/api/parsing/job/${jobId}/result/markdown`,\n        method: \"GET\",\n        headers: {\n            \"Authorization\": `Bearer ${process.env.LLAMAPARSE_API_KEY}`,\n        },\n        logger: meta.logger.child({ method: \"scrapePDFWithLlamaParse/result/robustFetch\" }),\n        schema: z.object({\n            markdown: z.string(),\n        }),\n        tryCount: 32,\n        tryCooldown: 250,\n    });\n    \n    return {\n        markdown: result.markdown,\n        html: await marked.parse(result.markdown, { async: true }),\n    };\n}\n\nasync function scrapePDFWithParsePDF(meta: Meta, tempFilePath: string): Promise<PDFProcessorResult> {\n    meta.logger.debug(\"Processing PDF document with parse-pdf\", { tempFilePath });\n\n    const result = await PdfParse(await fs.readFile(tempFilePath));\n    const escaped = escapeHtml(result.text);\n\n    return {\n        markdown: escaped,\n        html: escaped,\n    };\n}\n\nexport async function scrapePDF(meta: Meta): Promise<EngineScrapeResult> {\n    if (!meta.options.parsePDF) {\n        const file = await fetchFileToBuffer(meta.url);\n        const content = file.buffer.toString(\"base64\");\n        return {\n            url: file.response.url,\n            statusCode: file.response.status,\n\n            html: content,\n            markdown: content,\n        };\n    }\n\n    const { response, tempFilePath } = await downloadFile(meta.id, meta.url);\n\n    let result: PDFProcessorResult | null = null;\n    if (process.env.LLAMAPARSE_API_KEY) {\n        try {\n            result = await scrapePDFWithLlamaParse({\n                ...meta,\n                logger: meta.logger.child({ method: \"scrapePDF/scrapePDFWithLlamaParse\" }),\n            }, tempFilePath);\n        } catch (error) {\n            meta.logger.warn(\"LlamaParse failed to parse PDF -- falling back to parse-pdf\", { error });\n            Sentry.captureException(error);\n        }\n    }\n\n    if (result === null) {\n        result = await scrapePDFWithParsePDF({\n            ...meta,\n            logger: meta.logger.child({ method: \"scrapePDF/scrapePDFWithParsePDF\" }),\n        }, tempFilePath);\n    }\n\n    await fs.unlink(tempFilePath);\n\n    return {\n        url: response.url,\n        statusCode: response.status,\n\n        html: result.html,\n        markdown: result.markdown,\n    }\n}\n"]}
{"version":3,"file":"queue-jobs.js","sourceRoot":"","sources":["../../../src/services/queue-jobs.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AACA,mDAAiD;AACjD,+BAAoC;AAEpC,qDAAuC;AACvC,gEAA4L;AAE5L,KAAK,UAAU,eAAe,CAC5B,iBAAsB,EACtB,OAAY,EACZ,KAAa,EACb,cAAsB,EAAE;IAExB,IAAI,kBAAkB,GAAG,KAAK,CAAC;IAE/B,IAAI,iBAAiB,IAAI,iBAAiB,CAAC,OAAO,IAAI,iBAAiB,CAAC,IAAI,EAAE,CAAC;QAC7E,MAAM,GAAG,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC;QACvB,MAAM,KAAK,GAAG,MAAM,IAAA,0CAAsB,EAAC,iBAAiB,CAAC,IAAI,CAAC,CAAC;QACnE,IAAA,mDAA+B,EAAC,iBAAiB,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC;QAChE,kBAAkB,GAAG,CAAC,MAAM,IAAA,iDAA6B,EAAC,iBAAiB,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC,CAAC,MAAM,IAAI,KAAK,CAAC;IAC7G,CAAC;IAED,IAAI,kBAAkB,EAAE,CAAC;QACvB,MAAM,IAAA,6CAAyB,EAAC,iBAAiB,CAAC,OAAO,EAAE;YACzD,EAAE,EAAE,KAAK;YACT,IAAI,EAAE,iBAAiB;YACvB,IAAI,EAAE;gBACJ,GAAG,OAAO;gBACV,QAAQ,EAAE,WAAW;gBACrB,KAAK,EAAE,KAAK;aACb;YACD,QAAQ,EAAE,WAAW;SACtB,CAAC,CAAC;IACL,CAAC;SAAM,CAAC;QACN,IAAI,iBAAiB,IAAI,iBAAiB,CAAC,OAAO,IAAI,iBAAiB,CAAC,IAAI,EAAE,CAAC;YAC7E,MAAM,IAAA,iDAA6B,EAAC,iBAAiB,CAAC,OAAO,EAAE,KAAK,CAAC,CAAC;QACxE,CAAC;QAED,MAAM,IAAA,8BAAc,GAAE,CAAC,GAAG,CAAC,KAAK,EAAE,iBAAiB,EAAE;YACnD,GAAG,OAAO;YACV,QAAQ,EAAE,WAAW;YACrB,KAAK;SACN,CAAC,CAAC;IACL,CAAC;AACH,CAAC;AAEM,KAAK,UAAU,YAAY,CAChC,iBAAoC,EACpC,UAAe,EAAE,EACjB,QAAgB,IAAA,SAAM,GAAE,EACxB,cAAsB,EAAE;IAExB,IAAI,MAAM,CAAC,aAAa,EAAE,EAAE,CAAC;QAC3B,MAAM,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,iBAAiB,CAAC,CAAC,MAAM,CAAC;QACtD,OAAO,MAAM,MAAM,CAAC,SAAS,CAAC;YAC5B,IAAI,EAAE,gBAAgB;YACtB,EAAE,EAAE,eAAe;YACnB,UAAU,EAAE;gBACV,sBAAsB,EAAE,KAAK;gBAC7B,4BAA4B,EAAE,IAAA,8BAAc,GAAE,CAAC,IAAI;gBACnD,6BAA6B,EAAE,IAAI;aACpC;SACF,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;YAChB,MAAM,eAAe,CAAC;gBACpB,GAAG,iBAAiB;gBACpB,MAAM,EAAE;oBACN,KAAK,EAAE,MAAM,CAAC,iBAAiB,CAAC,IAAI,CAAC;oBACrC,OAAO,EAAE,MAAM,CAAC,mBAAmB,CAAC,IAAI,CAAC;oBACzC,IAAI;iBACL;aACF,EAAE,OAAO,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;QAClC,CAAC,CAAC,CAAC;IACL,CAAC;SAAM,CAAC;QACN,MAAM,eAAe,CAAC,iBAAiB,EAAE,OAAO,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;IACxE,CAAC;AACH,CAAC;AA7BD,oCA6BC;AAEM,KAAK,UAAU,aAAa,CACjC,IAMG;IAEH,eAAe;IACf,MAAM,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,YAAY,CAAC,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC,IAAI,CAAC,KAAK,EAAE,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;AAC1G,CAAC;AAXD,sCAWC;AAED,SAAgB,UAAU,CAAc,KAAa,EAAE,OAAe;IACpE,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;QACrC,MAAM,KAAK,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC;QACzB,MAAM,GAAG,GAAG,WAAW,CAAC,KAAK,IAAI,EAAE;YACjC,IAAI,IAAI,CAAC,GAAG,EAAE,IAAI,KAAK,GAAG,OAAO,EAAE,CAAC;gBAClC,aAAa,CAAC,GAAG,CAAC,CAAC;gBACnB,MAAM,CAAC,IAAI,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC;YACjC,CAAC;iBAAM,CAAC;gBACN,MAAM,KAAK,GAAG,MAAM,IAAA,8BAAc,GAAE,CAAC,WAAW,CAAC,KAAK,CAAC,CAAC;gBACxD,IAAI,KAAK,KAAK,WAAW,EAAE,CAAC;oBAC1B,aAAa,CAAC,GAAG,CAAC,CAAC;oBACnB,OAAO,CAAC,CAAC,MAAM,IAAA,8BAAc,GAAE,CAAC,MAAM,CAAC,KAAK,CAAC,CAAE,CAAC,WAAW,CAAC,CAAC;gBAC/D,CAAC;qBAAM,IAAI,KAAK,KAAK,QAAQ,EAAE,CAAC;oBAC9B,8EAA8E;oBAC9E,MAAM,GAAG,GAAG,MAAM,IAAA,8BAAc,GAAE,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;oBACjD,IAAI,GAAG,IAAI,GAAG,CAAC,YAAY,KAAK,uBAAuB,EAAE,CAAC;wBACxD,aAAa,CAAC,GAAG,CAAC,CAAC;wBACnB,MAAM,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC;oBAC3B,CAAC;gBACH,CAAC;YACH,CAAC;QACH,CAAC,EAAE,GAAG,CAAC,CAAC;IACV,CAAC,CAAC,CAAA;AACJ,CAAC;AAvBD,gCAuBC","sourcesContent":["import { Job, JobsOptions } from \"bullmq\";\nimport { getScrapeQueue } from \"./queue-service\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport { WebScraperOptions } from \"../types\";\nimport * as Sentry from \"@sentry/node\";\nimport { cleanOldConcurrencyLimitEntries, getConcurrencyLimitActiveJobs, getConcurrencyLimitMax, pushConcurrencyLimitActiveJob, pushConcurrencyLimitedJob } from \"../lib/concurrency-limit\";\n\nasync function addScrapeJobRaw(\n  webScraperOptions: any,\n  options: any,\n  jobId: string,\n  jobPriority: number = 10\n) {\n  let concurrencyLimited = false;\n\n  if (webScraperOptions && webScraperOptions.team_id && webScraperOptions.plan) {\n    const now = Date.now();\n    const limit = await getConcurrencyLimitMax(webScraperOptions.plan);\n    cleanOldConcurrencyLimitEntries(webScraperOptions.team_id, now);\n    concurrencyLimited = (await getConcurrencyLimitActiveJobs(webScraperOptions.team_id, now)).length >= limit;\n  }\n\n  if (concurrencyLimited) {\n    await pushConcurrencyLimitedJob(webScraperOptions.team_id, {\n      id: jobId,\n      data: webScraperOptions,\n      opts: {\n        ...options,\n        priority: jobPriority,\n        jobId: jobId,\n      },\n      priority: jobPriority,\n    });\n  } else {\n    if (webScraperOptions && webScraperOptions.team_id && webScraperOptions.plan) {\n      await pushConcurrencyLimitActiveJob(webScraperOptions.team_id, jobId);\n    }\n\n    await getScrapeQueue().add(jobId, webScraperOptions, {\n      ...options,\n      priority: jobPriority,\n      jobId,\n    });\n  }\n}\n\nexport async function addScrapeJob(\n  webScraperOptions: WebScraperOptions,\n  options: any = {},\n  jobId: string = uuidv4(),\n  jobPriority: number = 10\n) {\n  if (Sentry.isInitialized()) {\n    const size = JSON.stringify(webScraperOptions).length;\n    return await Sentry.startSpan({\n      name: \"Add scrape job\",\n      op: \"queue.publish\",\n      attributes: {\n        \"messaging.message.id\": jobId,\n        \"messaging.destination.name\": getScrapeQueue().name,\n        \"messaging.message.body.size\": size,\n      },\n    }, async (span) => {\n      await addScrapeJobRaw({\n        ...webScraperOptions,\n        sentry: {\n          trace: Sentry.spanToTraceHeader(span),\n          baggage: Sentry.spanToBaggageHeader(span),\n          size,\n        },\n      }, options, jobId, jobPriority);\n    });\n  } else {\n    await addScrapeJobRaw(webScraperOptions, options, jobId, jobPriority);\n  }\n}\n\nexport async function addScrapeJobs(\n  jobs: {\n    data: WebScraperOptions,\n    opts: {\n      jobId: string,\n      priority: number,\n    },\n  }[],\n) {\n  // TODO: better\n  await Promise.all(jobs.map(job => addScrapeJob(job.data, job.opts, job.opts.jobId, job.opts.priority)));\n}\n\nexport function waitForJob<T = unknown>(jobId: string, timeout: number): Promise<T> {\n  return new Promise((resolve, reject) => {\n    const start = Date.now();\n    const int = setInterval(async () => {\n      if (Date.now() >= start + timeout) {\n        clearInterval(int);\n        reject(new Error(\"Job wait \"));\n      } else {\n        const state = await getScrapeQueue().getJobState(jobId);\n        if (state === \"completed\") {\n          clearInterval(int);\n          resolve((await getScrapeQueue().getJob(jobId))!.returnvalue);\n        } else if (state === \"failed\") {\n          // console.log(\"failed\", (await getScrapeQueue().getJob(jobId)).failedReason);\n          const job = await getScrapeQueue().getJob(jobId);\n          if (job && job.failedReason !== \"Concurrency limit hit\") {\n            clearInterval(int);\n            reject(job.failedReason);\n          }\n        }\n      }\n    }, 250);\n  })\n}\n"]}
{"version":3,"file":"scrape_log.js","sourceRoot":"","sources":["../../../../src/services/logging/scrape_log.ts"],"names":[],"mappings":";;;AAAA,yBAAuB;AAEvB,0CAA+C;AAE/C,6CAA0C;AAC1C,mCAAsC;AACtC,IAAA,qBAAY,GAAE,CAAC;AAER,KAAK,UAAU,SAAS,CAC7B,SAAoB,EACpB,WAAyB;IAEzB,MAAM,mBAAmB,GAAG,OAAO,CAAC,GAAG,CAAC,qBAAqB,KAAK,MAAM,CAAC;IACzE,IAAI,CAAC,mBAAmB,EAAE,CAAC;QACzB,eAAM,CAAC,KAAK,CAAC,qCAAqC,CAAC,CAAC;QACpD,OAAO;IACT,CAAC;IACD,IAAI,CAAC;QACH,8BAA8B;QAC9B,0CAA0C;QAC1C,YAAY;QACZ,IAAI;QACJ,qDAAqD;QACrD,IACE,WAAW;YACX,WAAW,CAAC,OAAO;YACnB,WAAW,CAAC,OAAO,CAAC,eAAe,CAAC,EACpC,CAAC;YACD,SAAS,CAAC,IAAI,GAAG,sCAAsC,CAAC;QAC1D,CAAC;QAED,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,2BAAgB,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,MAAM,CAAC;YACxE;gBACE,GAAG,EAAE,SAAS,CAAC,GAAG;gBAClB,OAAO,EAAE,SAAS,CAAC,OAAO;gBAC1B,OAAO,EAAE,SAAS,CAAC,OAAO;gBAC1B,aAAa,EAAE,SAAS,CAAC,aAAa;gBACtC,kBAAkB,EAAE,SAAS,CAAC,kBAAkB;gBAChD,KAAK,EAAE,SAAS,CAAC,KAAK;gBACtB,OAAO,EAAE,SAAS,CAAC,OAAO;gBAC1B,aAAa,EAAE,SAAS,CAAC,aAAa;gBACtC,UAAU,EAAE,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE;gBACpC,IAAI,EAAE,0BAA0B;gBAChC,YAAY,EAAE,SAAS,CAAC,YAAY;gBACpC,YAAY,EAAE,SAAS,CAAC,YAAY;aACrC;SACF,CAAC,CAAC;QAEH,IAAI,KAAK,EAAE,CAAC;YACV,eAAM,CAAC,KAAK,CAAC,yBAAyB,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;QACjE,CAAC;IACH,CAAC;IAAC,OAAO,KAAK,EAAE,CAAC;QACf,eAAM,CAAC,KAAK,CAAC,yBAAyB,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;IACjE,CAAC;AACH,CAAC;AA9CD,8BA8CC","sourcesContent":["import \"dotenv/config\";\nimport { ScrapeLog } from \"../../types\";\nimport { supabase_service } from \"../supabase\";\nimport { PageOptions } from \"../../lib/entities\";\nimport { logger } from \"../../lib/logger\";\nimport { configDotenv } from \"dotenv\";\nconfigDotenv();\n\nexport async function logScrape(\n  scrapeLog: ScrapeLog,\n  pageOptions?: PageOptions\n) {\n  const useDbAuthentication = process.env.USE_DB_AUTHENTICATION === 'true';\n  if (!useDbAuthentication) {\n    logger.debug(\"Skipping logging scrape to Supabase\");\n    return;\n  }\n  try {\n    // Only log jobs in production\n    // if (process.env.ENV !== \"production\") {\n    //   return;\n    // }\n    // Redact any pages that have an authorization header\n    if (\n      pageOptions &&\n      pageOptions.headers &&\n      pageOptions.headers[\"Authorization\"]\n    ) {\n      scrapeLog.html = \"REDACTED DUE TO AUTHORIZATION HEADER\";\n    }\n\n    const { data, error } = await supabase_service.from(\"scrape_logs\").insert([\n      {\n        url: scrapeLog.url,\n        scraper: scrapeLog.scraper,\n        success: scrapeLog.success,\n        response_code: scrapeLog.response_code,\n        time_taken_seconds: scrapeLog.time_taken_seconds,\n        proxy: scrapeLog.proxy,\n        retried: scrapeLog.retried,\n        error_message: scrapeLog.error_message,\n        date_added: new Date().toISOString(),\n        html: \"Removed to save db space\",\n        ipv4_support: scrapeLog.ipv4_support,\n        ipv6_support: scrapeLog.ipv6_support,\n      },\n    ]);\n\n    if (error) {\n      logger.error(`Error logging proxy:\\n${JSON.stringify(error)}`);\n    }\n  } catch (error) {\n    logger.error(`Error logging proxy:\\n${JSON.stringify(error)}`);\n  }\n}\n"]}
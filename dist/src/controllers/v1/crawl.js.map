{"version":3,"file":"crawl.js","sourceRoot":"","sources":["../../../../src/controllers/v1/crawl.ts"],"names":[],"mappings":";;;AACA,+BAAoC;AACpC,mCAMiB;AACjB,uDAQ+B;AAC/B,gEAA4D;AAC5D,gEAA8D;AAC9D,0DAAyD;AACzD,6CAA0C;AAC1C,yDAAwD;AACxD,oDAAqD;AACrD,mCAA+D;AAExD,KAAK,UAAU,eAAe,CACnC,GAAqD,EACrD,GAA4B;IAE5B,GAAG,CAAC,IAAI,GAAG,0BAAkB,CAAC,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IAE9C,MAAM,EAAE,GAAG,IAAA,SAAM,GAAE,CAAC;IAEpB,MAAM,IAAA,oBAAQ,EAAC,EAAE,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;IAErC,IAAI,EAAE,gBAAgB,EAAE,GAAG,GAAG,CAAC,OAAQ,CAAC;IACxC,MAAM,mBAAmB,GAAG,OAAO,CAAC,GAAG,CAAC,qBAAqB,KAAK,MAAM,CAAC;IACzE,IAAG,CAAC,mBAAmB,EAAC,CAAC;QACvB,gBAAgB,GAAG,QAAQ,CAAC;IAC9B,CAAC;IAED,MAAM,cAAc,GAAG;QACrB,GAAG,GAAG,CAAC,IAAI;QACX,GAAG,EAAE,SAAS;QACd,aAAa,EAAE,SAAS;KACzB,CAAC;IACF,MAAM,aAAa,GAAG,GAAG,CAAC,IAAI,CAAC,aAAa,CAAC;IAE7C,6CAA6C;IAC7C,IAAI,KAAK,CAAC,OAAO,CAAC,cAAc,CAAC,YAAY,CAAC,EAAE,CAAC;QAC/C,KAAK,MAAM,CAAC,IAAI,cAAc,CAAC,YAAY,EAAE,CAAC;YAC5C,IAAI,CAAC;gBACH,IAAI,MAAM,CAAC,CAAC,CAAC,CAAC;YAChB,CAAC;YAAC,OAAO,CAAC,EAAE,CAAC;gBACX,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,CAAC,CAAC,OAAO,EAAE,CAAC,CAAC;YACpE,CAAC;QACH,CAAC;IACH,CAAC;IAED,IAAI,KAAK,CAAC,OAAO,CAAC,cAAc,CAAC,YAAY,CAAC,EAAE,CAAC;QAC/C,KAAK,MAAM,CAAC,IAAI,cAAc,CAAC,YAAY,EAAE,CAAC;YAC5C,IAAI,CAAC;gBACH,IAAI,MAAM,CAAC,CAAC,CAAC,CAAC;YAChB,CAAC;YAAC,OAAO,CAAC,EAAE,CAAC;gBACX,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,CAAC,CAAC,OAAO,EAAE,CAAC,CAAC;YACpE,CAAC;QACH,CAAC;IACH,CAAC;IAED,cAAc,CAAC,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,gBAAgB,EAAE,cAAc,CAAC,KAAK,CAAC,CAAC;IAExE,MAAM,EAAE,GAAgB;QACtB,SAAS,EAAE,GAAG,CAAC,IAAI,CAAC,GAAG;QACvB,cAAc,EAAE,IAAA,8BAAsB,EAAC,cAAc,CAAC;QACtD,aAAa;QACb,eAAe,EAAE,EAAE;QACnB,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;QACzB,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE;QACrB,IAAI,EAAE,GAAG,CAAC,IAAI,CAAC,IAAI;KACpB,CAAC;IAEF,MAAM,OAAO,GAAG,IAAA,4BAAc,EAAC,EAAE,EAAE,EAAE,CAAC,CAAC;IAEvC,IAAI,CAAC;QACH,EAAE,CAAC,MAAM,GAAG,MAAM,OAAO,CAAC,YAAY,CAAC,aAAa,CAAC,mBAAmB,CAAC,CAAC;IAC5E,CAAC;IAAC,OAAO,CAAC,EAAE,CAAC;QACX,eAAM,CAAC,KAAK,CACV,8DAA8D,IAAI,CAAC,SAAS,CAC1E,CAAC,CACF,EAAE,CACJ,CAAC;IACJ,CAAC;IAED,MAAM,IAAA,uBAAS,EAAC,EAAE,EAAE,EAAE,CAAC,CAAC;IAExB,MAAM,OAAO,GAAG,EAAE,CAAC,cAAc,CAAC,aAAa;QAC7C,CAAC,CAAC,IAAI;QACN,CAAC,CAAC,MAAM,OAAO,CAAC,aAAa,EAAE,CAAC;IAElC,IAAI,OAAO,KAAK,IAAI,IAAI,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;QAC3C,IAAI,WAAW,GAAG,EAAE,CAAC;QACnB,uDAAuD;QACvD,kDAAkD;QAClD,IAAG,OAAO,CAAC,MAAM,GAAG,IAAI,EAAC,CAAC;YACxB,iBAAiB;YACjB,WAAW,GAAG,MAAM,IAAA,6BAAc,EAAC,EAAC,IAAI,EAAE,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO,EAAE,YAAY,EAAE,EAAE,EAAC,CAAC,CAAA;QACxG,CAAC;QACH,MAAM,IAAI,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE;YAC7B,MAAM,GAAG,GAAG,CAAC,CAAC,GAAG,CAAC;YAClB,MAAM,IAAI,GAAG,IAAA,SAAM,GAAE,CAAC;YACtB,OAAO;gBACL,IAAI,EAAE,IAAI;gBACV,IAAI,EAAE;oBACJ,GAAG;oBACH,IAAI,EAAE,aAAa;oBACnB,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;oBACzB,IAAI,EAAE,GAAG,CAAC,IAAI,CAAC,IAAI;oBACnB,cAAc;oBACd,aAAa;oBACb,MAAM,EAAE,KAAK;oBACb,QAAQ,EAAE,EAAE;oBACZ,UAAU,EAAE,IAAI;oBAChB,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;oBACzB,EAAE,EAAE,IAAI;iBACT;gBACD,IAAI,EAAE;oBACJ,KAAK,EAAE,IAAI;oBACX,QAAQ,EAAE,EAAE;iBACb;aACF,CAAC;QACJ,CAAC,CAAC,CAAC;QAEH,MAAM,IAAA,sBAAQ,EACZ,EAAE,EACF,EAAE,EACF,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAC5B,CAAC;QACF,MAAM,IAAA,0BAAY,EAChB,EAAE,EACF,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAC9B,CAAC;QACF,MAAM,IAAA,8BAAc,GAAE,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IACvC,CAAC;SAAM,CAAC;QACN,MAAM,IAAA,qBAAO,EAAC,EAAE,EAAE,EAAE,EAAE,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QACpC,MAAM,KAAK,GAAG,IAAA,SAAM,GAAE,CAAC;QACvB,MAAM,IAAA,yBAAY,EAChB;YACE,GAAG,EAAE,GAAG,CAAC,IAAI,CAAC,GAAG;YACjB,IAAI,EAAE,aAAa;YACnB,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,cAAc;YACd,aAAa,EAAE,qBAAmB,CAAC,KAAK,CAAC,aAAa,CAAC;YACvD,IAAI,EAAE,GAAG,CAAC,IAAI,CAAC,IAAK;YACpB,MAAM,EAAE,KAAK;YACb,QAAQ,EAAE,EAAE;YACZ,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,EAAE,EAAE,IAAI;SACT,EACD;YACE,QAAQ,EAAE,EAAE;SACb,EACD,KAAK,CACN,CAAC;QACF,MAAM,IAAA,yBAAW,EAAC,EAAE,EAAE,KAAK,CAAC,CAAC;IAC/B,CAAC;IAED,IAAG,GAAG,CAAC,IAAI,CAAC,OAAO,EAAE,CAAC;QACpB,MAAM,IAAA,qBAAW,EAAC,GAAG,CAAC,IAAI,CAAC,OAAO,EAAE,EAAE,EAAE,IAAI,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,EAAE,eAAe,CAAC,CAAC;IACzF,CAAC;IAED,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,CAAC,GAAG,KAAK,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,OAAO,CAAC;IAEtE,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;QAC1B,OAAO,EAAE,IAAI;QACb,EAAE;QACF,GAAG,EAAE,GAAG,QAAQ,MAAM,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,aAAa,EAAE,EAAE;KACvD,CAAC,CAAC;AACL,CAAC;AAxJD,0CAwJC","sourcesContent":["import { Response } from \"express\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport {\n  CrawlRequest,\n  crawlRequestSchema,\n  CrawlResponse,\n  RequestWithAuth,\n  toLegacyCrawlerOptions,\n} from \"./types\";\nimport {\n  addCrawlJob,\n  addCrawlJobs,\n  crawlToCrawler,\n  lockURL,\n  lockURLs,\n  saveCrawl,\n  StoredCrawl,\n} from \"../../lib/crawl-redis\";\nimport { logCrawl } from \"../../services/logging/crawl_log\";\nimport { getScrapeQueue } from \"../../services/queue-service\";\nimport { addScrapeJob } from \"../../services/queue-jobs\";\nimport { logger } from \"../../lib/logger\";\nimport { getJobPriority } from \"../../lib/job-priority\";\nimport { callWebhook } from \"../../services/webhook\";\nimport { scrapeOptions as scrapeOptionsSchema } from \"./types\";\n\nexport async function crawlController(\n  req: RequestWithAuth<{}, CrawlResponse, CrawlRequest>,\n  res: Response<CrawlResponse>\n) {\n  req.body = crawlRequestSchema.parse(req.body);\n\n  const id = uuidv4();\n\n  await logCrawl(id, req.auth.team_id);\n\n  let { remainingCredits } = req.account!;\n  const useDbAuthentication = process.env.USE_DB_AUTHENTICATION === 'true';\n  if(!useDbAuthentication){\n    remainingCredits = Infinity;\n  }\n\n  const crawlerOptions = {\n    ...req.body,\n    url: undefined,\n    scrapeOptions: undefined,\n  };\n  const scrapeOptions = req.body.scrapeOptions;\n\n  // TODO: @rafa, is this right? copied from v0\n  if (Array.isArray(crawlerOptions.includePaths)) {\n    for (const x of crawlerOptions.includePaths) {\n      try {\n        new RegExp(x);\n      } catch (e) {\n        return res.status(400).json({ success: false, error: e.message });\n      }\n    }\n  }\n\n  if (Array.isArray(crawlerOptions.excludePaths)) {\n    for (const x of crawlerOptions.excludePaths) {\n      try {\n        new RegExp(x);\n      } catch (e) {\n        return res.status(400).json({ success: false, error: e.message });\n      }\n    }\n  }\n\n  crawlerOptions.limit = Math.min(remainingCredits, crawlerOptions.limit);\n  \n  const sc: StoredCrawl = {\n    originUrl: req.body.url,\n    crawlerOptions: toLegacyCrawlerOptions(crawlerOptions),\n    scrapeOptions,\n    internalOptions: {},\n    team_id: req.auth.team_id,\n    createdAt: Date.now(),\n    plan: req.auth.plan,\n  };\n\n  const crawler = crawlToCrawler(id, sc);\n\n  try {\n    sc.robots = await crawler.getRobotsTxt(scrapeOptions.skipTlsVerification);\n  } catch (e) {\n    logger.debug(\n      `[Crawl] Failed to get robots.txt (this is probably fine!): ${JSON.stringify(\n        e\n      )}`\n    );\n  }\n\n  await saveCrawl(id, sc);\n\n  const sitemap = sc.crawlerOptions.ignoreSitemap\n    ? null\n    : await crawler.tryGetSitemap();\n\n  if (sitemap !== null && sitemap.length > 0) {\n    let jobPriority = 20;\n      // If it is over 1000, we need to get the job priority,\n      // otherwise we can use the default priority of 20\n      if(sitemap.length > 1000){\n        // set base to 21\n        jobPriority = await getJobPriority({plan: req.auth.plan, team_id: req.auth.team_id, basePriority: 21})\n      }\n    const jobs = sitemap.map((x) => {\n      const url = x.url;\n      const uuid = uuidv4();\n      return {\n        name: uuid,\n        data: {\n          url,\n          mode: \"single_urls\",\n          team_id: req.auth.team_id,\n          plan: req.auth.plan,\n          crawlerOptions,\n          scrapeOptions,\n          origin: \"api\",\n          crawl_id: id,\n          sitemapped: true,\n          webhook: req.body.webhook,\n          v1: true,\n        },\n        opts: {\n          jobId: uuid,\n          priority: 20,\n        },\n      };\n    });\n\n    await lockURLs(\n      id,\n      sc,\n      jobs.map((x) => x.data.url)\n    );\n    await addCrawlJobs(\n      id,\n      jobs.map((x) => x.opts.jobId)\n    );\n    await getScrapeQueue().addBulk(jobs);\n  } else {\n    await lockURL(id, sc, req.body.url);\n    const jobId = uuidv4();\n    await addScrapeJob(\n      {\n        url: req.body.url,\n        mode: \"single_urls\",\n        team_id: req.auth.team_id,\n        crawlerOptions,\n        scrapeOptions: scrapeOptionsSchema.parse(scrapeOptions),\n        plan: req.auth.plan!,\n        origin: \"api\",\n        crawl_id: id,\n        webhook: req.body.webhook,\n        v1: true,\n      },\n      {\n        priority: 15,\n      },\n      jobId,\n    );\n    await addCrawlJob(id, jobId);\n  }\n\n  if(req.body.webhook) {\n    await callWebhook(req.auth.team_id, id, null, req.body.webhook, true, \"crawl.started\");\n  }\n\n  const protocol = process.env.ENV === \"local\" ? req.protocol : \"https\";\n  \n  return res.status(200).json({\n    success: true,\n    id,\n    url: `${protocol}://${req.get(\"host\")}/v1/crawl/${id}`,\n  });\n}\n\n\n"]}
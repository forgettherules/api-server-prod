{"version":3,"file":"models.js","sourceRoot":"","sources":["../../../../src/lib/LLM-extraction/models.ts"],"names":[],"mappings":";;;AAEA,uCAAgD;AAOhD,MAAM,SAAS,GAAG,KAAK,CAAC;AACxB,MAAM,QAAQ,GAAG,CAAC,CAAC;AACnB,MAAM,aAAa,GACjB,yEAAyE,CAAC;AAE5E,SAAS,gBAAgB,CACvB,QAAkB,EAClB,IAA6B;IAE7B,IAAI,QAAQ,GAAG,QAAQ,CAAC,QAAQ,CAAC;IAEjC,IAAI,gBAAgB,GAAG,QAAQ,CAAC,QAAQ,CAAC;IAEzC,IAAI,IAAI,KAAK,UAAU,EAAE,CAAC;QACxB,gBAAgB,GAAG,QAAQ,CAAC,OAAO,CAAC;IACtC,CAAC;IAED,uDAAuD;IACvD,IAAI,CAAC,gBAAgB,EAAE,CAAC;QACtB,OAAO,IAAI,CAAC;QACZ,mBAAmB;QACnB,4JAA4J;QAC5J,KAAK;IACP,CAAC;IAED,yBAAyB;IACzB,MAAM,SAAS,GAAG,IAAA,6BAAmB,EAAC,gBAAgB,EAAE,OAAO,CAAC,CAAC;IAEjE,IAAI,SAAS,GAAG,SAAS,EAAE,CAAC;QAC1B,0EAA0E;QAC1E,gBAAgB,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC,EAAE,SAAS,GAAG,QAAQ,CAAC,CAAC;IACrE,CAAC;IACD,OAAO,CAAC,CAAC,EAAE,IAAI,EAAE,MAAM,EAAE,IAAI,EAAE,gBAAgB,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;AACjE,CAAC;AAEM,KAAK,UAAU,yBAAyB,CAAC,EAC9C,MAAM,EACN,KAAK,GAAG,OAAO,CAAC,GAAG,CAAC,UAAU,IAAI,aAAa,EAC/C,QAAQ,EACR,MAAM,EAAE,sCAAsC;AAC9C,YAAY,GAAG,aAAa,EAC5B,MAAM,EACN,WAAW,EACX,IAAI,GAUL;IACC,MAAM,MAAM,GAAG,MAAgB,CAAC;IAChC,MAAM,WAAW,GAAG,gBAAgB,CAAC,QAAQ,EAAE,IAAI,CAAC,CAAC;IAErD,IAAI,WAAW,KAAK,IAAI,EAAE,CAAC;QACzB,OAAO;YACL,GAAG,QAAQ;YACX,OAAO,EACL,oFAAoF;SACvF,CAAC;IACJ,CAAC;IACD,MAAM,CAAC,OAAO,EAAE,SAAS,CAAC,GAAG,WAAW,CAAC;IAEzC,IAAI,UAAU,CAAC;IACf,IAAI,aAAa,CAAC;IAClB,IAAI,MAAM,IAAI,CAAC,MAAM,EAAE,CAAC;QACtB,MAAM,cAAc,GAAG,MAAM,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YAC1D,KAAK;YACL,QAAQ,EAAE;gBACR;oBACE,IAAI,EAAE,QAAQ;oBACd,OAAO,EAAE,YAAY;iBACtB;gBACD,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE;gBACzB;oBACE,IAAI,EAAE,MAAM;oBACZ,OAAO,EAAE,gGAAgG,MAAM,EAAE;iBAClH;aACF;YACD,eAAe,EAAE,EAAE,IAAI,EAAE,aAAa,EAAE;YACxC,WAAW;SACZ,CAAC,CAAC;QAEH,IAAI,CAAC;YACH,aAAa,GAAG,IAAI,CAAC,KAAK,CACxB,CAAC,cAAc,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,IAAI,EAAE,CAAC,CAAC,IAAI,EAAE,CACzD,CAAC;QACJ,CAAC;QAAC,OAAO,CAAC,EAAE,CAAC;YACX,MAAM,IAAI,KAAK,CAAC,cAAc,CAAC,CAAC;QAClC,CAAC;IACH,CAAC;SAAM,CAAC;QACN,UAAU,GAAG,MAAM,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YAChD,KAAK;YACL,QAAQ,EAAE;gBACR;oBACE,IAAI,EAAE,QAAQ;oBACd,OAAO,EAAE,YAAY;iBACtB;gBACD,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE;aAC1B;YACD,KAAK,EAAE;gBACL;oBACE,IAAI,EAAE,UAAU;oBAChB,QAAQ,EAAE;wBACR,IAAI,EAAE,iBAAiB;wBACvB,WAAW,EAAE,gDAAgD;wBAC7D,UAAU,EAAE,MAAM;qBACnB;iBACF;aACF;YACD,WAAW,EAAE,EAAE,IAAI,EAAE,UAAU,EAAE,QAAQ,EAAE,EAAE,IAAI,EAAE,iBAAiB,EAAE,EAAE;YACxE,WAAW;SACZ,CAAC,CAAC;QACH,MAAM,CAAC,GAAG,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC;QAEzE,kEAAkE;QAClE,IAAI,CAAC;YACH,aAAa,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAChC,CAAC;QAAC,OAAO,CAAC,EAAE,CAAC;YACX,MAAM,IAAI,KAAK,CAAC,cAAc,CAAC,CAAC;QAClC,CAAC;IACH,CAAC;IAED,4DAA4D;IAC5D,OAAO;QACL,GAAG,QAAQ;QACX,cAAc,EAAE,aAAa;QAC7B,OAAO,EACL,SAAS,GAAG,SAAS;YACnB,CAAC,CAAC,kFAAkF,SAAS,sBAAsB,SAAS,qFAAqF;YACjN,CAAC,CAAC,SAAS;KAChB,CAAC;AACJ,CAAC;AApGD,8DAoGC","sourcesContent":["import OpenAI from \"openai\";\nimport { Document } from \"../../lib/entities\";\nimport { numTokensFromString } from \"./helpers\";\n\nexport type ScraperCompletionResult = {\n  data: any | null;\n  url: string;\n};\n\nconst maxTokens = 32000;\nconst modifier = 4;\nconst defaultPrompt =\n  \"You are a professional web scraper. Extract the contents of the webpage\";\n\nfunction prepareOpenAIDoc(\n  document: Document,\n  mode: \"markdown\" | \"raw-html\"\n): [OpenAI.Chat.Completions.ChatCompletionContentPart[], number] | null {\n  let markdown = document.markdown;\n\n  let extractionTarget = document.markdown;\n\n  if (mode === \"raw-html\") {\n    extractionTarget = document.rawHtml;\n  }\n\n  // Check if the markdown content exists in the document\n  if (!extractionTarget) {\n    return null;\n    // throw new Error(\n    //   `${mode} content is missing in the document. This is likely due to an error in the scraping process. Please try again or reach out to help@mendable.ai`\n    // );\n  }\n\n  // count number of tokens\n  const numTokens = numTokensFromString(extractionTarget, \"gpt-4\");\n\n  if (numTokens > maxTokens) {\n    // trim the document to the maximum number of tokens, tokens != characters\n    extractionTarget = extractionTarget.slice(0, maxTokens * modifier);\n  }\n  return [[{ type: \"text\", text: extractionTarget }], numTokens];\n}\n\nexport async function generateOpenAICompletions({\n  client,\n  model = process.env.MODEL_NAME || \"gpt-4o-mini\",\n  document,\n  schema, //TODO - add zod dynamic type checking\n  systemPrompt = defaultPrompt,\n  prompt,\n  temperature,\n  mode,\n}: {\n  client: OpenAI;\n  model?: string;\n  document: Document;\n  schema: any; // This should be replaced with a proper Zod schema type when available\n  prompt?: string;\n  systemPrompt?: string;\n  temperature?: number;\n  mode: \"markdown\" | \"raw-html\";\n}): Promise<Document> {\n  const openai = client as OpenAI;\n  const preparedDoc = prepareOpenAIDoc(document, mode);\n\n  if (preparedDoc === null) {\n    return {\n      ...document,\n      warning:\n        \"LLM extraction was not performed since the document's content is empty or missing.\",\n    };\n  }\n  const [content, numTokens] = preparedDoc;\n\n  let completion;\n  let llmExtraction;\n  if (prompt && !schema) {\n    const jsonCompletion = await openai.chat.completions.create({\n      model,\n      messages: [\n        {\n          role: \"system\",\n          content: systemPrompt,\n        },\n        { role: \"user\", content },\n        {\n          role: \"user\",\n          content: `Transform the above content into structured json output based on the following user request: ${prompt}`,\n        },\n      ],\n      response_format: { type: \"json_object\" },\n      temperature,\n    });\n\n    try {\n      llmExtraction = JSON.parse(\n        (jsonCompletion.choices[0].message.content ?? \"\").trim()\n      );\n    } catch (e) {\n      throw new Error(\"Invalid JSON\");\n    }\n  } else {\n    completion = await openai.chat.completions.create({\n      model,\n      messages: [\n        {\n          role: \"system\",\n          content: systemPrompt,\n        },\n        { role: \"user\", content },\n      ],\n      tools: [\n        {\n          type: \"function\",\n          function: {\n            name: \"extract_content\",\n            description: \"Extracts the content from the given webpage(s)\",\n            parameters: schema,\n          },\n        },\n      ],\n      tool_choice: { type: \"function\", function: { name: \"extract_content\" } },\n      temperature,\n    });\n    const c = completion.choices[0].message.tool_calls[0].function.arguments;\n\n    // Extract the LLM extraction content from the completion response\n    try {\n      llmExtraction = JSON.parse(c);\n    } catch (e) {\n      throw new Error(\"Invalid JSON\");\n    }\n  }\n\n  // Return the document with the LLM extraction content added\n  return {\n    ...document,\n    llm_extraction: llmExtraction,\n    warning:\n      numTokens > maxTokens\n        ? `Page was trimmed to fit the maximum token limit defined by the LLM model (Max: ${maxTokens} tokens, Attemped: ${numTokens} tokens). If results are not good, email us at help@mendable.ai so we can help you.`\n        : undefined,\n  };\n}\n"]}